{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary and new connection predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Emails\n",
    "\n",
    "The data for this project is a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "The network also contains the node attributes `Department` and `ManagementSalary`.\n",
    "\n",
    "`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a management position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# CAREFULL the network is an old one built with networkx 1.x, so you need to install networkx 1.11 to run it\n",
    "G = nx.read_gpickle('email_prediction.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary Prediction\n",
    "\n",
    "Using network G, we can predict whether or not individuals are receiving a management position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Convertion of the network into a dataframe\n",
    "df = pd.DataFrame(index=G.nodes())\n",
    "df['mana'] = pd.Series(nx.get_node_attributes(G, 'ManagementSalary'))\n",
    "df['dep'] = pd.Series(nx.get_node_attributes(G, 'Department'))\n",
    "\n",
    "# Adding new features to improve the model \n",
    "df[\"degree\"] = pd.Series(G.degree())\n",
    "df[\"degree_cent\"] = pd.Series(nx.degree_centrality(G))\n",
    "df[\"clustering\"] = pd.Series(nx.clustering(G))\n",
    "    \n",
    "df_test = df[np.isnan(df[\"mana\"])][[\"degree\", 'dep', \"degree_cent\", \"clustering\"]]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 119 753\n"
     ]
    }
   ],
   "source": [
    "# Disparity test\n",
    "print(len(df[df[\"mana\"]==0.0]), len(df[df[\"mana\"]==1.0]), len(df))\n",
    "    \n",
    "# Balancing the data by undersampling the larger class to twice the size of the smaller one\n",
    "df_training = pd.concat([df[df[\"mana\"]==1.0], df[df[\"mana\"]==0.0].sample(n=2*len(df[df[\"mana\"]==1.0]), random_state=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param : {'C': 5}\n",
      "Mean ROC AUC lr: 0.885\n"
     ]
    }
   ],
   "source": [
    "# Creation and fitting of the models\n",
    "X = df_training[[\"degree\", 'dep', \"degree_cent\", \"clustering\"]]\n",
    "y = df_training[\"mana\"]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "### Decision tree ###\n",
    "#dt_clf = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "# looking for best params\n",
    "#grid_values = {\"max_depth\":[1, 2, 3, 4, 5, None]}\n",
    "#grid_rdf = GridSearchCV(dt_clf, param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "#print(\"Best param :\",grid_rdf.best_params_)\n",
    "# Evaluation\n",
    "#scores = cross_val_score(dt_clf, X, y, scoring='roc_auc')\n",
    "#print('Mean ROC AUC dt: %.3f' % mean(scores))\n",
    "    \n",
    "### Logistic Regression ###\n",
    "lr_clf = LogisticRegression(C=5).fit(X_train, y_train)\n",
    "# looking for best params\n",
    "grid_values = {\"C\":[1, 2, 3, 5, 8, 10, 20]}\n",
    "grid_lr = GridSearchCV(lr_clf, param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "print(\"Best param :\",grid_lr.best_params_)\n",
    "# Evaluation\n",
    "scores = cross_val_score(lr_clf, X, y, scoring='roc_auc')\n",
    "print('Mean ROC AUC lr: %.3f' % mean(scores))\n",
    "    \n",
    "### Random Decision tree ###\n",
    "#rdfclf = RandomForestClassifier(n_estimators=500, random_state=0).fit(X_train, y_train)\n",
    "# looking for best params\n",
    "#grid_values = {\"n_estimators\":[50, 100, 200, 500]}\n",
    "#grid_rdf = GridSearchCV(rdfclf, param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "#print(\"Best param :\",grid_rdf.best_params_)\n",
    "# Evaluation\n",
    "#scores = cross_val_score(lr_clf, X, y, scoring='roc_auc')\n",
    "#print('Mean ROC AUC rdt: %.3f' % mean(scores))\n",
    "    \n",
    "### MLP ###\n",
    "#nnclf = MLPClassifier(hidden_layer_sizes = [10, 10], solver=\"lbfgs\", random_state=0).fit(X_train_scaled, y_train)\n",
    "# looking for best params\n",
    "#grid_values = {\"hidden_layer_sizes\":[[10], [10,5], [10,10]], \"solver\":[\"lbfgs\", \"sgd\", \"adam\"]}\n",
    "#grid_nn = GridSearchCV(nnclf, param_grid = grid_values, scoring = 'roc_auc').fit(X_train_scaled, y_train)\n",
    "#print(\"Best param :\",grid_nn.best_params_)\n",
    "# Evaluation\n",
    "#scores = cross_val_score(nnclf, X, y, scoring='roc_auc')\n",
    "#print('Mean ROC AUC nn: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       0.290414\n",
      "2       0.847866\n",
      "5       0.994735\n",
      "8       0.270844\n",
      "14      0.619467\n",
      "          ...   \n",
      "992     0.011725\n",
      "994     0.012051\n",
      "996     0.011399\n",
      "1000    0.096163\n",
      "1001    0.257491\n",
      "Length: 252, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Prediction of the probability of individuals having a management salary\n",
    "predict_mana_lr = lr_clf.predict_proba(df_test)\n",
    "    \n",
    "print(pd.Series(predict_mana_lr[:,1], df_test.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Connections Prediction\n",
    "\n",
    "Prediction of future connections between employees of the network. The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>(6, 840)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(4, 197)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(620, 979)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(519, 872)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(382, 423)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(97, 226)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(349, 905)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(429, 860)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(309, 989)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>(468, 880)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "(97, 226)                 1.0\n",
       "(349, 905)                0.0\n",
       "(429, 860)                0.0\n",
       "(309, 989)                0.0\n",
       "(468, 880)                0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the new features using the jaccard coeff, resource allocation and preferential attachment methods\n",
    "df = future_connections.copy()\n",
    "jacc = list(nx.jaccard_coefficient(G))\n",
    "resource_all = list(nx.resource_allocation_index(G))\n",
    "pref_atta = list(nx.preferential_attachment(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes\n",
    "df = future_connections.copy()\n",
    "df = pd.merge(pd.DataFrame(data=[i[-1] for i in jacc], index=[(i[0],i[1]) for i in jacc], columns=[\"jaccard\"]), df, left_index=True, right_index=True)\n",
    "df = pd.merge(pd.DataFrame(data=[i[-1] for i in resource_all], index=[(i[0],i[1]) for i in resource_all], columns=[\"resource_all\"]), df, left_index=True, right_index=True)\n",
    "df = pd.merge(pd.DataFrame(data=[i[-1] for i in pref_atta], index=[(i[0],i[1]) for i in pref_atta], columns=[\"pref_atta\"]), df, left_index=True, right_index=True)\n",
    "    \n",
    "df_test = df[np.isnan(df[\"Future Connection\"])][[\"pref_atta\", 'resource_all', \"jaccard\"]]\n",
    "    \n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disparity test\n",
    "#print(len(df[df[\"Future Connection\"]==0.0]), len(df[df[\"Future Connection\"]==1.0]), len(df))\n",
    "    \n",
    "# Balancing the data\n",
    "df_training = pd.concat([df[df[\"Future Connection\"]==1.0], df[df[\"Future Connection\"]==0.0].sample(n=len(df[df[\"Future Connection\"]==1.0])*2, random_state=3)])\n",
    "    \n",
    "X = df_training[[\"pref_atta\", 'resource_all', \"jaccard\"]]\n",
    "y = df_training[\"Future Connection\"]\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "### Logistic Regression ###\n",
    "lr_clf = LogisticRegression(C=1).fit(X_train, y_train)\n",
    "# looking for best params\n",
    "#grid_values = {\"C\":[1, 2, 3, 5, 8, 10, 20]}\n",
    "#grid_lr = GridSearchCV(lr_clf, param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "#print(\"Best param :\",grid_lr.best_params_)\n",
    "# Evaluation\n",
    "#scores = cross_val_score(lr_clf, X, y, scoring='roc_auc')\n",
    "#print('Mean ROC AUC lr: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 9)          0.258917\n",
      "(0, 19)         0.467299\n",
      "(0, 20)         0.723175\n",
      "(0, 35)         0.128700\n",
      "(0, 38)         0.088970\n",
      "                  ...   \n",
      "(998, 999)      0.063564\n",
      "(1000, 1002)    0.063616\n",
      "(1000, 1003)    0.063616\n",
      "(1000, 1004)    0.063616\n",
      "(1001, 1002)    0.063658\n",
      "Length: 122112, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Prediction of the probability of individuals having new connections\n",
    "predict_new_links = lr_clf.predict_proba(df_test)\n",
    "    \n",
    "print(pd.Series(predict_new_links[:,1], df_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
